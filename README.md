직행(https://zighang.com/) 이라는 채용정보사이트를 활용한 ai관련 직업을 리스트업 하고, 해당 취업이 공시하는 지원자격 및 우대사항을 확인한다.

이를 통해, 해당 직군으로 취업하기 위해 필요한 기술을 확인하고 취업 전략을 수립한다.

`SINGLE_20250826_004620.xlsx`는 listly라는 chrome 확장 프로그램을 사용해 획득한 정보(CompanyName, ApplicationLink, Job Title, ExperienceLevel, EmploymentType, Location)가 포함된 HTMLAttribute를 저장한 sheet이다.

1. 해당 시트에서 정보를 정리/나열한다.
2. 지원자격과 우대사항을 획득 및 추가한다.
3. 해당 정보들을 분석하여 필요로하는 기술을 파악한다.



### 08/26

## 완료 작업
### 1. 직행에서 [회사, 제목, 경력, 근무형태, 학력, 근무지역, 링크]의 형태로 sheet를 만들었다. 여기서 링크는, 직행 내의 공고글의 링크이다.
### 2. 직행 내의 공고의 데이터는 원본 공고의 캡쳐본이기에, 해당 페이지의 '지원하기'버튼을 통해 원본에 접속하고 원본페이지의 주소와 html(지원자격, 우대사항 포함)을 긁어오는 과정을 완성했다.

## 여기서 마주친 한계
### 2번 작업의 과정에서 html을 그대로 gpt-oss모델에 전송하여 지원자격과 우대사항을 정리한 json을 얻으려 하였다(`llm_qual_spec.py`). 
### 이 떄, html의 크기가 한계를 초과 하여, 요구사항을 수행하지 못하였다.
### 완전히 다른 회사들이 소유한 공고이기에, html을 정제하는데에 어려움이 있다.

## 해결 방법
### 일단 기존 sheet에 원문링크를 추가하고, 해당 페이지의 html을 따로 저장한다(4~5개 정도?).
### 기존의 html텍스트(168467)을 4096으로 토큰수를 줄여야 한다......

## 추가적으로
### 'ollama run gpt-oss'로 gpt-oss를 사용할 때와, 'ollama serve'를 통해 사용할 떄 통신방식의 차이를 감안하더라도 속도에서 너무 큰 차이가 난다.
### 이에 같은 로컬 모델이 사용되고 있는 것이 맞는지, 맞다면 왜 이런 차이가 발생하는지 분석할 필요가 있다.
